{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(EXAMPLE_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Mr. Smith, how are you doing today?',\n",
       " 'The weather is great, and Python is awesome.',\n",
       " 'The sky is pinkish-blue.',\n",
       " \"You shouldn't eat cardboard.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# POS tag list:\n",
    "\n",
    "# CC\tcoordinating conjunction\n",
    "# CD\tcardinal digit\n",
    "# DT\tdeterminer\n",
    "# EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "# FW\tforeign word\n",
    "# IN\tpreposition/subordinating conjunction\n",
    "# JJ\tadjective\t'big'\n",
    "# JJR\tadjective, comparative\t'bigger'\n",
    "# JJS\tadjective, superlative\t'biggest'\n",
    "# LS\tlist marker\t1)\n",
    "# MD\tmodal\tcould, will\n",
    "# NN\tnoun, singular 'desk'\n",
    "# NNS\tnoun plural\t'desks'\n",
    "# NNP\tproper noun, singular\t'Harrison'\n",
    "# NNPS\tproper noun, plural\t'Americans'\n",
    "# PDT\tpredeterminer\t'all the kids'\n",
    "# POS\tpossessive ending\tparent\\'s\n",
    "# PRP\tpersonal pronoun\tI, he, she\n",
    "# PRP$\tpossessive pronoun\tmy, his, hers\n",
    "# RB\tadverb\tvery, silently,\n",
    "# RBR\tadverb, comparative\tbetter\n",
    "# RBS\tadverb, superlative\tbest\n",
    "# RP\tparticle\tgive up\n",
    "# TO\tto\tgo 'to' the store.\n",
    "# UH\tinterjection\terrrrrrrrm\n",
    "# VB\tverb, base form\ttake\n",
    "# VBD\tverb, past tense\ttook\n",
    "# VBG\tverb, gerund/present participle\ttaking\n",
    "# VBN\tverb, past participle\ttaken\n",
    "# VBP\tverb, sing. present, non-3d\ttake\n",
    "# VBZ\tverb, 3rd person sing. present\ttakes\n",
    "# WDT\twh-determiner\twhich\n",
    "# WP\twh-pronoun\twho, what\n",
    "# WP$\tpossessive wh-pronoun\twhose\n",
    "# WRB\twh-abverb\twhere, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token():\n",
    "    try:\n",
    "        for i in sentences:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            tokenized.append(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Hello', 'NNP'),\n",
       "  ('Mr.', 'NNP'),\n",
       "  ('Smith', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('how', 'WRB'),\n",
       "  ('are', 'VBP'),\n",
       "  ('you', 'PRP'),\n",
       "  ('doing', 'VBG'),\n",
       "  ('today', 'NN'),\n",
       "  ('?', '.')],\n",
       " [('The', 'DT'),\n",
       "  ('weather', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('great', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('and', 'CC'),\n",
       "  ('Python', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('awesome', 'JJ'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DT'),\n",
       "  ('sky', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('pinkish-blue', 'JJ'),\n",
       "  ('.', '.')],\n",
       " [('You', 'PRP'),\n",
       "  ('should', 'MD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('eat', 'VB'),\n",
       "  ('cardboard', 'NN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk Hello/NNP Mr./NNP Smith/NNP)\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  doing/VBG\n",
      "  today/NN\n",
      "  ?/.)\n",
      "(Chunk Hello/NNP Mr./NNP Smith/NNP)\n",
      "(S\n",
      "  The/DT\n",
      "  weather/NN\n",
      "  is/VBZ\n",
      "  great/JJ\n",
      "  ,/,\n",
      "  and/CC\n",
      "  (Chunk Python/NNP)\n",
      "  is/VBZ\n",
      "  awesome/JJ\n",
      "  ./.)\n",
      "(Chunk Python/NNP)\n",
      "(S The/DT sky/NN is/VBZ pinkish-blue/JJ ./.)\n",
      "(S You/PRP should/MD n't/RB eat/VB cardboard/NN ./.)\n"
     ]
    }
   ],
   "source": [
    "# chunking -- NOT USED --\n",
    "\n",
    "for i in tokenized:\n",
    "    chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "    chunkParser = nltk.RegexpParser(chunkGram)\n",
    "    chunked = chunkParser.parse(i)\n",
    "    print(chunked)\n",
    "    \n",
    "    for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "        print(subtree)\n",
    "        \n",
    "    chunked.draw()\n",
    "    \n",
    "## NOT USED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Named Entity recognition \n",
    "\n",
    "for i in tokenized:\n",
    "    namedEnt = nltk.ne_chunk(i, binary=True)\n",
    "    namedEnt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Mr.\n",
      "Smith\n",
      ",\n",
      "how\n",
      "are\n",
      "you\n",
      "doing\n",
      "today\n",
      "?\n",
      "The\n",
      "weather\n",
      "is\n",
      "great\n",
      ",\n",
      "and\n",
      "Python\n",
      "is\n",
      "awesome\n",
      ".\n",
      "The\n",
      "sky\n",
      "is\n",
      "pinkish-blue\n",
      ".\n",
      "You\n",
      "should\n",
      "n't\n",
      "eat\n",
      "cardboard\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Lammatizing -- for finding root word of noun\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in tokenized:\n",
    "    for word in i:\n",
    "        print(lemmatizer.lemmatize(word[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Synset.name of Synset('broadcast.n.02')>\n",
      "plan\n"
     ]
    }
   ],
   "source": [
    "# wordnet\n",
    "syns = wordnet.synsets(\"program\")\n",
    "print(syns[2].name)\n",
    "print(syns[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wornet for synonyms\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for i in syn.lemmas():\n",
    "        synonyms.append(i.name())\n",
    "        if i.antonyms():\n",
    "            antonyms.append(i.antonyms()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while synonyms.count('good') > 0:\n",
    "    synonyms.remove('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goodness',\n",
       " 'goodness',\n",
       " 'commodity',\n",
       " 'trade_good',\n",
       " 'full',\n",
       " 'estimable',\n",
       " 'honorable',\n",
       " 'respectable',\n",
       " 'beneficial',\n",
       " 'just',\n",
       " 'upright',\n",
       " 'adept',\n",
       " 'expert',\n",
       " 'practiced',\n",
       " 'proficient',\n",
       " 'skillful',\n",
       " 'skilful',\n",
       " 'dear',\n",
       " 'near',\n",
       " 'dependable',\n",
       " 'safe',\n",
       " 'secure',\n",
       " 'right',\n",
       " 'ripe',\n",
       " 'well',\n",
       " 'effective',\n",
       " 'in_effect',\n",
       " 'in_force',\n",
       " 'serious',\n",
       " 'sound',\n",
       " 'salutary',\n",
       " 'honest',\n",
       " 'undecomposed',\n",
       " 'unspoiled',\n",
       " 'unspoilt',\n",
       " 'well',\n",
       " 'thoroughly',\n",
       " 'soundly']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# similarity using wordnet\n",
    "w1 = wordnet.synset('ship.n.1')\n",
    "w2 = wordnet.synset('boat.n.1')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences of triples: ['NNP-NNP-NNP', 'NNP-NNP-,', 'NNP-,-WRB', ',-WRB-VBP', 'WRB-VBP-PRP', 'VBP-PRP-VBG', 'PRP-VBG-NN']\n",
      "\n",
      "sequences of triples: ['NNP-NNP-NNP', 'NNP-NNP-,', 'NNP-,-WRB', ',-WRB-VBP', 'WRB-VBP-PRP', 'VBP-PRP-VBG', 'PRP-VBG-NN', 'DT-NN-VBZ', 'NN-VBZ-JJ', 'VBZ-JJ-,', 'JJ-,-CC', ',-CC-NNP', 'CC-NNP-VBZ', 'NNP-VBZ-JJ']\n",
      "\n",
      "sequences of triples: ['NNP-NNP-NNP', 'NNP-NNP-,', 'NNP-,-WRB', ',-WRB-VBP', 'WRB-VBP-PRP', 'VBP-PRP-VBG', 'PRP-VBG-NN', 'DT-NN-VBZ', 'NN-VBZ-JJ', 'VBZ-JJ-,', 'JJ-,-CC', ',-CC-NNP', 'CC-NNP-VBZ', 'NNP-VBZ-JJ', 'DT-NN-VBZ', 'NN-VBZ-JJ']\n",
      "\n",
      "sequences of triples: ['NNP-NNP-NNP', 'NNP-NNP-,', 'NNP-,-WRB', ',-WRB-VBP', 'WRB-VBP-PRP', 'VBP-PRP-VBG', 'PRP-VBG-NN', 'DT-NN-VBZ', 'NN-VBZ-JJ', 'VBZ-JJ-,', 'JJ-,-CC', ',-CC-NNP', 'CC-NNP-VBZ', 'NNP-VBZ-JJ', 'DT-NN-VBZ', 'NN-VBZ-JJ', 'PRP-MD-RB', 'MD-RB-VB', 'RB-VB-NN']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_triple_strings = []\n",
    "for sent in tokenized:  \n",
    "    pos = [ i[1] for i in sent ]\n",
    "    n = len(pos)\n",
    "    for i in range(0,n-3):\n",
    "        t = \"-\".join(pos[i:i+3]) # pull out 3 list item from counter, convert to string\n",
    "        list_of_triple_strings.append(t)\n",
    "\n",
    "    print(\"sequences of triples:\", list_of_triple_strings)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Its might be better to strip \",\" and other punctuation mark.. \n",
    "\n",
    "# list_of_triple_strings = []\n",
    "# for sent in tokenized:\n",
    "#     msent\n",
    "#     pos = [ i[1] for i in msent ]\n",
    "#     n = len(pos)\n",
    "#     for i in range(0,n-3):\n",
    "#         t = \"-\".join(pos[i:i+3]) # pull out 3 list item from counter, convert to string\n",
    "#         list_of_triple_strings.append(t)\n",
    "\n",
    "#     print(\"sequences of triples:\", list_of_triple_strings)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry, I don't know about the weather.</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That is a tricky question to answer.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does OCM stand for</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAX is a Mobile Application Accelerator</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can a dog see in colour?</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  SENTENCE CLASS\n",
       "0   Sorry, I don't know about the weather.     S\n",
       "1     That is a tricky question to answer.     C\n",
       "2                  What does OCM stand for     Q\n",
       "3  MAX is a Mobile Application Accelerator     S\n",
       "4                 Can a dog see in colour?     Q"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read senctence.csv\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('sentences.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def triple(tokenize):\n",
    "    list_of_triple = []\n",
    "    triple_strings = []\n",
    "    for sent in tokenize:  \n",
    "        pos = [ i[1] for i in sent ]\n",
    "        n = len(pos)\n",
    "        for i in range(0,n-3):\n",
    "            t = \"-\".join(pos[i:i+3]) # pull out 3 list item from counter, convert to string\n",
    "            triple_strings.append(t)\n",
    "\n",
    "        list_of_triple.append(triple_strings)\n",
    "    return list_of_triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NNP-NNP-NNP',\n",
       "  'NNP-NNP-,',\n",
       "  'NNP-,-WRB',\n",
       "  ',-WRB-VBP',\n",
       "  'WRB-VBP-PRP',\n",
       "  'VBP-PRP-VBG',\n",
       "  'PRP-VBG-NN',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'VBZ-JJ-,',\n",
       "  'JJ-,-CC',\n",
       "  ',-CC-NNP',\n",
       "  'CC-NNP-VBZ',\n",
       "  'NNP-VBZ-JJ',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'PRP-MD-RB',\n",
       "  'MD-RB-VB',\n",
       "  'RB-VB-NN'],\n",
       " ['NNP-NNP-NNP',\n",
       "  'NNP-NNP-,',\n",
       "  'NNP-,-WRB',\n",
       "  ',-WRB-VBP',\n",
       "  'WRB-VBP-PRP',\n",
       "  'VBP-PRP-VBG',\n",
       "  'PRP-VBG-NN',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'VBZ-JJ-,',\n",
       "  'JJ-,-CC',\n",
       "  ',-CC-NNP',\n",
       "  'CC-NNP-VBZ',\n",
       "  'NNP-VBZ-JJ',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'PRP-MD-RB',\n",
       "  'MD-RB-VB',\n",
       "  'RB-VB-NN'],\n",
       " ['NNP-NNP-NNP',\n",
       "  'NNP-NNP-,',\n",
       "  'NNP-,-WRB',\n",
       "  ',-WRB-VBP',\n",
       "  'WRB-VBP-PRP',\n",
       "  'VBP-PRP-VBG',\n",
       "  'PRP-VBG-NN',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'VBZ-JJ-,',\n",
       "  'JJ-,-CC',\n",
       "  ',-CC-NNP',\n",
       "  'CC-NNP-VBZ',\n",
       "  'NNP-VBZ-JJ',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'PRP-MD-RB',\n",
       "  'MD-RB-VB',\n",
       "  'RB-VB-NN'],\n",
       " ['NNP-NNP-NNP',\n",
       "  'NNP-NNP-,',\n",
       "  'NNP-,-WRB',\n",
       "  ',-WRB-VBP',\n",
       "  'WRB-VBP-PRP',\n",
       "  'VBP-PRP-VBG',\n",
       "  'PRP-VBG-NN',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'VBZ-JJ-,',\n",
       "  'JJ-,-CC',\n",
       "  ',-CC-NNP',\n",
       "  'CC-NNP-VBZ',\n",
       "  'NNP-VBZ-JJ',\n",
       "  'DT-NN-VBZ',\n",
       "  'NN-VBZ-JJ',\n",
       "  'PRP-MD-RB',\n",
       "  'MD-RB-VB',\n",
       "  'RB-VB-NN']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0fef3f2b209e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSENTENCE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-8e2926f648d9>\u001b[0m in \u001b[0;36mtriple\u001b[1;34m(tokenize)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtriple_strings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-8e2926f648d9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtriple_strings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "t = df.SENTENCE.head()\n",
    "for i in t:\n",
    "    print(triple(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = pd.read_csv('featuresDump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>stemmedCount</th>\n",
       "      <th>stemmedEndNN</th>\n",
       "      <th>CD</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>NNS</th>\n",
       "      <th>PRP</th>\n",
       "      <th>...</th>\n",
       "      <th>startTuple0</th>\n",
       "      <th>endTuple0</th>\n",
       "      <th>endTuple1</th>\n",
       "      <th>endTuple2</th>\n",
       "      <th>verbBeforeNoun</th>\n",
       "      <th>qMark</th>\n",
       "      <th>qVerbCombo</th>\n",
       "      <th>qTripleScore</th>\n",
       "      <th>sTripleScore</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44d8a78d2ca66b1b</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9133770c79b2c43</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246cf41a55627762</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53ac5757399632e8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78e580bde0b4396e</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id   wordCount   stemmedCount   stemmedEndNN   CD   NN  \\\n",
       "0   44d8a78d2ca66b1b           7              5              0    0    1   \n",
       "1   a9133770c79b2c43           7              4              1    0    1   \n",
       "2   246cf41a55627762           5              3              0    0    0   \n",
       "3   53ac5757399632e8           6              4              0    0    0   \n",
       "4   78e580bde0b4396e           6              4              0    0    3   \n",
       "\n",
       "    NNP   NNPS   NNS   PRP   ...     startTuple0   endTuple0   endTuple1  \\\n",
       "0     1      0     0     1   ...               0           0           0   \n",
       "1     0      0     0     0   ...               0           0           0   \n",
       "2     1      0     0     0   ...               0           0           0   \n",
       "3     3      0     0     0   ...               0           0           0   \n",
       "4     0      0     0     0   ...               0           1           0   \n",
       "\n",
       "    endTuple2   verbBeforeNoun   qMark   qVerbCombo   qTripleScore  \\\n",
       "0           0                0       0            1              0   \n",
       "1           0                1       0            1              0   \n",
       "2           0                1       0            1              1   \n",
       "3           0                0       0            1              0   \n",
       "4           0                1       1            1              0   \n",
       "\n",
       "    sTripleScore   class  \n",
       "0              1       S  \n",
       "1              2       C  \n",
       "2              0       Q  \n",
       "3              2       S  \n",
       "4              0       Q  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Cursor object at 0x0000023D03AB7340>\n"
     ]
    }
   ],
   "source": [
    "import databaseOperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "databaseOperation.insert_answer('hi', 'thei a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Cursor object at 0x0000023D03AB7420>\n",
      "<sqlite3.Cursor object at 0x0000023D03AB7420>\n"
     ]
    }
   ],
   "source": [
    "print(databaseOperation.no_of_rows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
